{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9UUcbMe5uHd"
      },
      "source": [
        "# Day4-1 : VGG, RESNET model simple Implementation with CIFAR10 dataset (45 min)\n",
        "#### 이번 실습에서는 CNN 아키텍쳐 중 가장 대표적인 VGG과 RESNET 모델을 간단히 구현해보고 CIFAR-10 데이터셋에 대해 학습 및 Inference를 해볼 계획입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMY3CPV4ebV2"
      },
      "source": [
        "## Example 1) VGG16 모델 구현\n",
        "- [doc] (https://arxiv.org/pdf/1409.1556.pdf)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1E6MVIcFCsImwWQGOhC-8KUQqAe2W_I28)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1jT9jhqMzEaHoma5xvro5jf6PFOq7FlLJ)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jbce4wfMMTqv",
        "outputId": "ffab937e-520c-43ab-86a7-5071db6ea914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13021840.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, utils\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DEVICE 설정\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "# Parameter 설정\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.0001\n",
        "\n",
        "# Transform 설정\n",
        "transform_CIFAR10 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Dataset 설정\n",
        "train_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                         train = True,\n",
        "                                         download = True,\n",
        "                                         transform = transform_CIFAR10)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                train = False,\n",
        "                                download = True,\n",
        "                                transform = transform_CIFAR10)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_JeDJmfNuN0k",
        "outputId": "aafa9799-5d63-483f-9f15-330fde68f27a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
            "              ReLU-4           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-16            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-17            [-1, 256, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 2, 2]               0\n",
            "           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-26            [-1, 512, 2, 2]               0\n",
            "           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-28            [-1, 512, 2, 2]               0\n",
            "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-30            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 134,301,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.84\n",
            "Params size (MB): 512.32\n",
            "Estimated Total Size (MB): 517.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Model 구현\n",
        "class Custom_VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Custom_VGG, self).__init__()\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "        # Conv layer\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d(7)\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "    def forward(self, x):\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "        x = self.relu(self.conv1_1(x))\n",
        "        x = self.relu(self.conv1_2(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.relu(self.conv2_1(x))\n",
        "        x = self.relu(self.conv2_2(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.relu(self.conv3_1(x))\n",
        "        x = self.relu(self.conv3_2(x))\n",
        "        x = self.relu(self.conv3_3(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.relu(self.conv4_1(x))\n",
        "        x = self.relu(self.conv4_2(x))\n",
        "        x = self.relu(self.conv4_3(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.relu(self.conv5_1(x))\n",
        "        x = self.relu(self.conv5_2(x))\n",
        "        x = self.relu(self.conv5_3(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.adaptive_avg_pool(x)\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "\n",
        "        ########################################## Complete This Code~!\n",
        "        return x\n",
        "\n",
        "model = Custom_VGG().to(DEVICE)\n",
        "summary(model, (3,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jkqHEqDBaoPQ",
        "outputId": "272e4976-78f0-4db0-a457-ce6ab12428e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
            "              ReLU-4           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-16            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-17            [-1, 256, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 2, 2]               0\n",
            "           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-26            [-1, 512, 2, 2]               0\n",
            "           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-28            [-1, 512, 2, 2]               0\n",
            "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-30            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 134,301,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.84\n",
            "Params size (MB): 512.32\n",
            "Estimated Total Size (MB): 517.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "model_import = models.vgg16(pretrained=False, num_classes=10).to(DEVICE)\n",
        "summary(model_import, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_b5IsHnKUquV"
      },
      "outputs": [],
      "source": [
        "# Optimizer 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oy8oXE_mWARx",
        "outputId": "7e2b7f1b-8c50-44d6-95a5-237104bc4f65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301356\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.111874\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.756096\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.729194\n",
            "[1] Test Loss: 1.6864, Accuracy: 32.54%\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.715979\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.651258\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.572220\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.422531\n",
            "[2] Test Loss: 1.3848, Accuracy: 46.67%\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.285518\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.354075\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.316396\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.277216\n",
            "[3] Test Loss: 1.2320, Accuracy: 55.39%\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.246620\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.946330\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.911426\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.203128\n",
            "[4] Test Loss: 0.9447, Accuracy: 66.40%\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.820652\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.037769\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.921662\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.799570\n",
            "[5] Test Loss: 0.8387, Accuracy: 70.35%\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.699261\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.621714\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.909027\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.806392\n",
            "[6] Test Loss: 0.8046, Accuracy: 72.40%\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.820410\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.614495\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.629207\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.645182\n",
            "[7] Test Loss: 0.7741, Accuracy: 73.84%\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.605833\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.524643\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.532648\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.886140\n",
            "[8] Test Loss: 0.7640, Accuracy: 75.01%\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.490431\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.480456\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.435422\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.424911\n",
            "[9] Test Loss: 0.7682, Accuracy: 75.31%\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.489735\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.545541\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.401901\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.505265\n",
            "[10] Test Loss: 0.6958, Accuracy: 78.34%\n"
          ]
        }
      ],
      "source": [
        "# Train 구현\n",
        "def train_one_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluation 구현\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            # 배치 오차를 합산\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item()\n",
        "\n",
        "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNxz2ARrE9Jp"
      },
      "source": [
        "## Excercise 1) RESNET18 모델 구현\n",
        "- [doc] (https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1GgHATI5PFF8-PlBdGp9vDra2maRqLybl)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1EYxIKJEI0rwIyW7ZZaFeZgJvol6Jb-XL)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=12reHf9xtapZrVBG4LlNbNGa37ZeFfUqk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5_IJRFtgHw02",
        "outputId": "4c7296d1-1cc9-44f6-86bb-f317d761ce24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, utils\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DEVICE 설정\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "# Parameter 설정\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.01\n",
        "\n",
        "# Transform 설정\n",
        "transform_CIFAR10 = transforms.Compose([\n",
        "    # transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Dataset 설정\n",
        "train_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                         train = True,\n",
        "                                         download = True,\n",
        "                                         transform = transform_CIFAR10)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                train = False,\n",
        "                                download = True,\n",
        "                                transform = transform_CIFAR10)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1dykk5Om-cPG",
        "outputId": "e70138a3-7441-4dfc-e0b1-9ff6801a235c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 14, 14]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
            "              ReLU-3           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-4             [-1, 64, 6, 6]               0\n",
            "            Conv2d-5             [-1, 64, 6, 6]          36,928\n",
            "       BatchNorm2d-6             [-1, 64, 6, 6]             128\n",
            "              ReLU-7             [-1, 64, 6, 6]               0\n",
            "            Conv2d-8             [-1, 64, 6, 6]          36,928\n",
            "       BatchNorm2d-9             [-1, 64, 6, 6]             128\n",
            "             ReLU-10             [-1, 64, 6, 6]               0\n",
            "           Conv2d-11             [-1, 64, 6, 6]          36,928\n",
            "      BatchNorm2d-12             [-1, 64, 6, 6]             128\n",
            "             ReLU-13             [-1, 64, 6, 6]               0\n",
            "           Conv2d-14             [-1, 64, 6, 6]          36,928\n",
            "      BatchNorm2d-15             [-1, 64, 6, 6]             128\n",
            "             ReLU-16             [-1, 64, 6, 6]               0\n",
            "           Conv2d-17            [-1, 128, 3, 3]          73,856\n",
            "      BatchNorm2d-18            [-1, 128, 3, 3]             256\n",
            "             ReLU-19            [-1, 128, 3, 3]               0\n",
            "           Conv2d-20            [-1, 128, 3, 3]         147,584\n",
            "      BatchNorm2d-21            [-1, 128, 3, 3]             256\n",
            "             ReLU-22            [-1, 128, 3, 3]               0\n",
            "           Conv2d-23            [-1, 128, 3, 3]         147,584\n",
            "      BatchNorm2d-24            [-1, 128, 3, 3]             256\n",
            "             ReLU-25            [-1, 128, 3, 3]               0\n",
            "           Conv2d-26            [-1, 128, 3, 3]         147,584\n",
            "      BatchNorm2d-27            [-1, 128, 3, 3]             256\n",
            "             ReLU-28            [-1, 128, 3, 3]               0\n",
            "           Conv2d-29            [-1, 256, 2, 2]         295,168\n",
            "      BatchNorm2d-30            [-1, 256, 2, 2]             512\n",
            "             ReLU-31            [-1, 256, 2, 2]               0\n",
            "           Conv2d-32            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-33            [-1, 256, 2, 2]             512\n",
            "             ReLU-34            [-1, 256, 2, 2]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         590,080\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "             ReLU-40            [-1, 256, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 1, 1]       1,180,160\n",
            "      BatchNorm2d-42            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-43            [-1, 512, 1, 1]               0\n",
            "           Conv2d-44            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-45            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-46            [-1, 512, 1, 1]               0\n",
            "           Conv2d-47            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-48            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-49            [-1, 512, 1, 1]               0\n",
            "           Conv2d-50            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-51            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-52            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-53            [-1, 512, 1, 1]               0\n",
            "           Linear-54                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,011,722\n",
            "Trainable params: 11,011,722\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.77\n",
            "Params size (MB): 42.01\n",
            "Estimated Total Size (MB): 42.78\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Model 구현\n",
        "class Custom_RESNET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Custom_RESNET, self).__init__()\n",
        "        self.maxpool2d = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_3 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_4 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_2 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_3 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_4 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(64,128,3,padding=1, stride=2)\n",
        "        self.conv3_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.conv3_4 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_2 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_3 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_4 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(128,256,3,padding=1, stride=2)\n",
        "        self.conv4_2 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv4_4 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_2 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_3 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_4 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(256,512,3,padding=1, stride=2)\n",
        "        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_4 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_2 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_3 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_4 = nn.BatchNorm2d(num_features=512)\n",
        "\n",
        "        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "        x1 = self.relu(self.bn1(self.conv1(x)))\n",
        "        x1 = self.maxpool2d(x1)\n",
        "\n",
        "        x2_1 = self.relu(self.bn2_1(self.conv2_1(x1)))\n",
        "        x2_2 = self.relu(self.bn2_2(self.conv2_2(x2_1))) + x1\n",
        "        x2_3 = self.relu(self.bn2_3(self.conv2_3(x2_2)))\n",
        "        x2_4 = self.relu(self.bn2_4(self.conv2_4(x2_3))) + x2_2\n",
        "\n",
        "        x3_1 = self.relu(self.bn3_1(self.conv3_1(x2_4)))\n",
        "        x3_2 = self.relu(self.bn3_2(self.conv3_2(x3_1)))\n",
        "        x3_3 = self.relu(self.bn3_3(self.conv3_3(x3_2)))\n",
        "        x3_4 = self.relu(self.bn3_4(self.conv3_4(x3_3))) + x3_2\n",
        "\n",
        "        x4_1 = self.relu(self.bn4_1(self.conv4_1(x3_4)))\n",
        "        x4_2 = self.relu(self.bn4_2(self.conv4_2(x4_1)))\n",
        "        x4_3 = self.relu(self.bn4_3(self.conv4_3(x4_2)))\n",
        "        x4_4 = self.relu(self.bn4_4(self.conv4_4(x4_3))) + x4_2\n",
        "\n",
        "        x5_1 = self.relu(self.bn5_1(self.conv5_1(x4_4)))\n",
        "        x5_2 = self.relu(self.bn5_2(self.conv5_2(x5_1)))\n",
        "        x5_3 = self.relu(self.bn5_3(self.conv5_3(x5_2)))\n",
        "        x5_4 = self.relu(self.bn5_4(self.conv5_4(x5_3))) + x5_2\n",
        "\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "        x = self.adaptiveavgpool2d(x5_4)\n",
        "        x = x.view(-1,512)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = Custom_RESNET().to(DEVICE)\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YJq3fJZHHw7_",
        "outputId": "2dffa5f0-a8bb-499a-edd9-caf15c9b70c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 11,181,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 43.95\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "model_import = models.resnet18(pretrained=False, num_classes=10).to(DEVICE)\n",
        "summary(model_import, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pUam0mfLavpg"
      },
      "outputs": [],
      "source": [
        "# Model, Optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GM0Tm7RJHzv-",
        "outputId": "d8175206-1e9f-4c48-ab72-feb132c19cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.668922\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.611708\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.521805\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.354004\n",
            "[1] Test Loss: 1.3454, Accuracy: 51.97%\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.879050\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.021214\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.884004\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.206973\n",
            "[2] Test Loss: 1.0645, Accuracy: 62.42%\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.176931\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.932939\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.866069\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.844845\n",
            "[3] Test Loss: 0.9556, Accuracy: 67.04%\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.632763\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.893376\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.634430\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.615543\n",
            "[4] Test Loss: 1.0639, Accuracy: 64.88%\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.123219\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.598252\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.848791\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.731084\n",
            "[5] Test Loss: 0.9036, Accuracy: 69.57%\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.453473\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bd9929b8c5c5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-bd9929b8c5c5>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0m__array_interface__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train 구현\n",
        "def train_one_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluation 구현\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            # 배치 오차를 합산\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item()\n",
        "\n",
        "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}